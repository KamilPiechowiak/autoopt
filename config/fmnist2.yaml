general:
  dataset:
    name: FASHION_MNIST
    resolution: 28
    path: data
    noaugment: True
  model:
    name: SmallResnet20
    num_classes: 10
  repeats: 1
  repeats_start: 0
  results_path: results
  epochs: 50
  batch_size: 128
  num_workers: 2
  gcp: True
  tpu: False
  bucket_path: gs://autoopt
experiments:
  - optimizer:
      name: Adam
      lr: 0.0001
  - optimizer:
      name: Adam
      lr: 0.01
  - optimizer:
      name: Adam
      lr: 0.001
    scheduler:
      name: CosineAnnealingLR
      T_max: 50
      eta_min: 0.0001
  - optimizer:
      name: ExpertsLinearized
      inner_optimizer:
        name: Adam
        lr: 1
      lr_min: 0.0001
      lr_max: 0.1
      num_experts: 100
      is_stationary: 1
      alpha: 0.1
      cumulative_loss_decay: 0.994
  - optimizer:
      name: ExpertsLinearized
      inner_optimizer:
        name: Adam
        lr: 1
      lr_min: 0.0001
      lr_max: 0.1
      num_experts: 100
      is_stationary: 1
      alpha: 0.1
      cumulative_loss_decay: 0.994
      fixed_share_alpha: 0.1
  - optimizer:
      name: ExpertsAdam
      inner_optimizer:
        name: Adam
      num_experts: 100
      alpha: 0.1
      cumulative_loss_decay: 0.994
      ranges:
        lr:
          - 1.e-4
          - 1.e-1
        beta1:
          - 1.e-3
          - 1
        beta2:
          - 1.e-4
          - 1
        eps:
          - 1.e-9
          - 1.e-5
  - optimizer:
      name: ExpertsAdam
      inner_optimizer:
        name: Adam
      num_experts: 100
      alpha: 1
      cumulative_loss_decay: 0.994
      ranges:
        lr:
          - 1.e-4
          - 1.e-1
        beta1:
          - 1.e-3
          - 1
        beta2:
          - 1.e-4
          - 1
        eps:
          - 1.e-9
          - 1.e-5
  - optimizer:
      name: ExpertsAdamRandom
      inner_optimizer:
        name: Adam
      num_experts: 100
      alpha: 0.1
      cumulative_loss_decay: 0.994
      ranges:
        lr:
          - 1.e-4
          - 1.e-1
        beta1:
          - 1.e-3
          - 1
        beta2:
          - 1.e-4
          - 1
        eps:
          - 1.e-9
          - 1.e-5
  - optimizer:
      name: ExpertsAdamRandom
      inner_optimizer:
        name: Adam
      num_experts: 100
      alpha: 1
      cumulative_loss_decay: 0.994
      ranges:
        lr:
          - 1.e-4
          - 1.e-1
        beta1:
          - 1.e-3
          - 1
        beta2:
          - 1.e-4
          - 1
        eps:
          - 1.e-9
          - 1.e-5